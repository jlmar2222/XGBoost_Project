# XGBoost_Project
A journey towards XGBoost algorithm 

Sources:

Patrick Winston MIT Lecture on AdaBoosting ([->link](https://www.youtube.com/watch?v=UHBmv7qCey4)): XGBoost is a refinement of Gradient Boosting, but AdaBoost has analitics solutions and so it is usefull to get intuition and general idea.

Stanford 2018 Lecture on Decition Trees and Ensemble Methods ([->link](https://www.youtube.com/watch?v=wr9gUr-eWdA))

Gradient boosting machines, a tutorial ([->link](https://pmc.ncbi.nlm.nih.gov/articles/PMC3885826/))

XGBoost (original paper) ([->link](https://arxiv.org/pdf/1603.02754))

XGBoost from Scratch in Python Medium Article ([->link](https://medium.com/analytics-vidhya/what-makes-xgboost-so-extreme-e1544a4433bb))

Git Hub Repository of above ([->link](https://github.com/Ekeany/XGBoost-From-Scratch)). (Aunque la parte del Weighted Quantile Sketch es erronea)



DDSketch ([->link](https://blog.acolyer.org/2019/09/06/ddsketch/)), for getting intuition on skecths (stuff that compress bid amoun of data in smaller representations)

Python implementation of DDSketch ([->link](https://github.com/bentay85/wqsketch/blob/main/wqsketch/wqsketch.py))

